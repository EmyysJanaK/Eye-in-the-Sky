{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Satellite Image Segmentation Using Deep Learning\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This implements state-of-the-art deep learning techniques for semantic segmentation of satellite imagery.\n",
    "\n",
    "## Segmentation Methods\n",
    "\n",
    "1. **Traditional Methods**: Thresholding, clustering, edge detection\n",
    "2. **Deep Learning Methods**: U-Net, DeepLabV3+, SegNet\n",
    "\n",
    "## Mathematical Foundation\n",
    "\n",
    "In semantic segmentation, we assign a class label to each pixel in the image. For a pixel $(i,j)$, the predicted class is:\n",
    "\n",
    "$$\\hat{y}_{i,j} = \\arg\\max_{c} p(y_{i,j} = c | x)$$\n",
    "\n",
    "where $p(y_{i,j} = c | x)$ is the probability that pixel $(i,j)$ belongs to class $c$ given input image $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage import io, transform, segmentation, color\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "\n",
    "# Deep learning imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# Metrics and evaluation\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, jaccard_score\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Display Satellite Images\n",
    "\n",
    "Satellite images require special handling due to their unique characteristics:\n",
    "\n",
    "1. **Multiple bands**: Beyond RGB (e.g., NIR, SWIR)\n",
    "2. **Large dimensions**: Often much larger than standard images\n",
    "3. **Different resolutions**: Spatial, spectral, and temporal\n",
    "4. **Georeferencing**: Contains geographical metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteImageHandler:\n",
    "    \"\"\"\n",
    "    A class for loading and processing satellite images.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir=None):\n",
    "        \"\"\"\n",
    "        Initialize the satellite image handler.\n",
    "        \n",
    "        Args:\n",
    "            data_dir (str, optional): Directory containing satellite images.\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        \n",
    "    def load_image(self, image_path):\n",
    "        \"\"\"\n",
    "        Load a satellite image from path.\n",
    "        \n",
    "        Args:\n",
    "            image_path (str): Path to the image file.\n",
    "            \n",
    "        Returns:\n",
    "            numpy.ndarray: Loaded image.\n",
    "        \"\"\"\n",
    "        if image_path.lower().endswith('.tif'):\n",
    "            try:\n",
    "                with rasterio.open(image_path) as src:\n",
    "                    # Read all bands and convert to RGB if needed\n",
    "                    img = src.read()\n",
    "                    \n",
    "                    # Extract metadata\n",
    "                    self.metadata = {\n",
    "                        'crs': src.crs,\n",
    "                        'transform': src.transform,\n",
    "                        'bounds': src.bounds,\n",
    "                        'height': src.height,\n",
    "                        'width': src.width\n",
    "                    }\n",
    "                    \n",
    "                    # If more than 3 bands, take first 3 (assuming RGB)\n",
    "                    if img.shape[0] > 3:\n",
    "                        img = img[:3]\n",
    "                        \n",
    "                    # Transpose to (H, W, C) format for display\n",
    "                    img = np.transpose(img, (1, 2, 0))\n",
    "                    \n",
    "                    # Normalize to 0-255 range if needed\n",
    "                    if img.max() > 0:\n",
    "                        img = (img / img.max() * 255).astype(np.uint8)\n",
    "                        \n",
    "                    return img\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading GeoTIFF: {e}\")\n",
    "                # Fallback to regular image loading\n",
    "                img = cv2.imread(image_path)\n",
    "                return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            # For regular image formats\n",
    "            img = cv2.imread(image_path)\n",
    "            if img is not None:\n",
    "                return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            else:\n",
    "                raise ValueError(f\"Could not load image from {image_path}\")\n",
    "    \n",
    "    def display_image(self, image=None, image_path=None, title=\"Satellite Image\", figsize=(12, 10)):\n",
    "        \"\"\"\n",
    "        Display a satellite image.\n",
    "        \n",
    "        Args:\n",
    "            image (numpy.ndarray, optional): Image to display.\n",
    "            image_path (str, optional): Path to image file (if image not provided).\n",
    "            title (str): Title for the plot.\n",
    "            figsize (tuple): Figure size.\n",
    "        \"\"\"\n",
    "        if image is None and image_path is not None:\n",
    "            image = self.load_image(image_path)\n",
    "            \n",
    "        if image is None:\n",
    "            print(\"No image provided to display\")\n",
    "            return\n",
    "            \n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.imshow(image)\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print image stats\n",
    "        print(f\"Image shape: {image.shape}\")\n",
    "        print(f\"Image type: {image.dtype}\")\n",
    "        print(f\"Value range: [{image.min()}, {image.max()}]\")\n",
    "        \n",
    "    def create_false_color(self, img, bands=[3, 2, 1]):\n",
    "        \"\"\"\n",
    "        Create a false color composite from a multi-band image.\n",
    "        \n",
    "        Args:\n",
    "            img (numpy.ndarray): Multi-band image.\n",
    "            bands (list): List of band indices to use [R, G, B].\n",
    "            \n",
    "        Returns:\n",
    "            numpy.ndarray: False color image.\n",
    "        \"\"\"\n",
    "        if len(img.shape) < 3 or img.shape[0] < 4:  # Not enough bands\n",
    "            print(\"Not enough bands for false color composite\")\n",
    "            return img\n",
    "            \n",
    "        # Select bands (adjust indices to be 0-based)\n",
    "        bands = [b-1 for b in bands]\n",
    "        selected_bands = img[bands]\n",
    "        \n",
    "        # Normalize each band\n",
    "        normalized = np.zeros_like(selected_bands, dtype=np.float32)\n",
    "        for i in range(3):\n",
    "            band = selected_bands[i]\n",
    "            if band.max() > band.min():\n",
    "                normalized[i] = (band - band.min()) / (band.max() - band.min())\n",
    "                \n",
    "        # Convert to 8-bit and transpose to (H, W, C)\n",
    "        normalized = (normalized * 255).astype(np.uint8)\n",
    "        normalized = np.transpose(normalized, (1, 2, 0))\n",
    "        \n",
    "        return normalized\n",
    "\n",
    "# Create a satellite image handler\n",
    "handler = SatelliteImageHandler()\n",
    "\n",
    "# Define the image path - update with your actual image path\n",
    "image_path = '../data/sentinelsat/sample_image.tif'\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(image_path):\n",
    "    # Load and display the image\n",
    "    image_rgb = handler.load_image(image_path)\n",
    "    handler.display_image(image_rgb, title=\"Loaded Satellite Image\")\n",
    "else:\n",
    "    print(f\"Image file {image_path} not found. Please update the path.\")\n",
    "    # Use a sample image for demonstration\n",
    "    print(\"Using a sample image for demonstration...\")\n",
    "    sample_img = np.ones((512, 512, 3), dtype=np.uint8) * 128\n",
    "    # Add some features to the sample image\n",
    "    cv2.circle(sample_img, (256, 256), 100, (200, 100, 100), -1)\n",
    "    cv2.rectangle(sample_img, (100, 100), (400, 150), (100, 200, 100), -1)\n",
    "    image_rgb = sample_img\n",
    "    handler.display_image(image_rgb, title=\"Sample Image (Placeholder)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteImagePreprocessor:\n",
    "    \"\"\"\n",
    "    Class for preprocessing satellite images for segmentation tasks.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, patch_size=256, overlap=0.2, augment=True):\n",
    "        \"\"\"\n",
    "        Initialize the preprocessor.\n",
    "        \n",
    "        Args:\n",
    "            patch_size (int): Size of patches to extract (square).\n",
    "            overlap (float): Overlap between patches (0-1).\n",
    "            augment (bool): Whether to apply data augmentation.\n",
    "        \"\"\"\n",
    "        self.patch_size = patch_size\n",
    "        self.overlap = overlap\n",
    "        self.augment = augment\n",
    "        \n",
    "    def normalize_image(self, image, method='minmax'):\n",
    "        \"\"\"\n",
    "        Normalize image pixel values.\n",
    "        \n",
    "        Args:\n",
    "            image (numpy.ndarray): Input image.\n",
    "            method (str): Normalization method ('minmax', 'std', 'imagenet').\n",
    "            \n",
    "        Returns:\n",
    "            numpy.ndarray: Normalized image.\n",
    "        \"\"\"\n",
    "        if image is None:\n",
    "            return None\n",
    "            \n",
    "        # Make a copy to avoid modifying the original\n",
    "        img = image.copy().astype(np.float32)\n",
    "        \n",
    "        if method == 'minmax':\n",
    "            # Normalize to [0, 1] for each channel\n",
    "            for i in range(img.shape[2]):\n",
    "                if img[:,:,i].max() > img[:,:,i].min():\n",
    "                    img[:,:,i] = (img[:,:,i] - img[:,:,i].min()) / (img[:,:,i].max() - img[:,:,i].min())\n",
    "        \n",
    "        elif method == 'std':\n",
    "            # Standardize to zero mean and unit variance\n",
    "            for i in range(img.shape[2]):\n",
    "                mean = img[:,:,i].mean()\n",
    "                std = img[:,:,i].std() + 1e-8\n",
    "                img[:,:,i] = (img[:,:,i] - mean) / std\n",
    "                \n",
    "        elif method == 'imagenet':\n",
    "            # ImageNet normalization (assumes RGB input)\n",
    "            if img.shape[2] >= 3:\n",
    "                img = img / 255.0  # Scale to [0, 1]\n",
    "                mean = np.array([0.485, 0.456, 0.406])\n",
    "                std = np.array([0.229, 0.224, 0.225])\n",
    "                for i in range(3):\n",
    "                    img[:,:,i] = (img[:,:,i] - mean[i]) / std[i]\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def extract_patches(self, image, mask=None):\n",
    "        \"\"\"\n",
    "        Extract overlapping patches from image and mask.\n",
    "        \n",
    "        Args:\n",
    "            image (numpy.ndarray): Input image.\n",
    "            mask (numpy.ndarray, optional): Input mask.\n",
    "            \n",
    "        Returns:\n",
    "            list: List of image patches and (if provided) mask patches.\n",
    "        \"\"\"\n",
    "        if image is None:\n",
    "            return []\n",
    "            \n",
    "        h, w = image.shape[:2]\n",
    "        stride = int(self.patch_size * (1 - self.overlap))\n",
    "        \n",
    "        image_patches = []\n",
    "        mask_patches = []\n",
    "        \n",
    "        # Extract patches\n",
    "        for y in range(0, h - self.patch_size + 1, stride):\n",
    "            for x in range(0, w - self.patch_size + 1, stride):\n",
    "                image_patch = image[y:y+self.patch_size, x:x+self.patch_size]\n",
    "                image_patches.append(image_patch)\n",
    "                \n",
    "                if mask is not None:\n",
    "                    mask_patch = mask[y:y+self.patch_size, x:x+self.patch_size]\n",
    "                    mask_patches.append(mask_patch)\n",
    "        \n",
    "        # Handle edge cases: add patches that include the right and bottom borders\n",
    "        if h % self.patch_size != 0:\n",
    "            for x in range(0, w - self.patch_size + 1, stride):\n",
    "                image_patch = image[h-self.patch_size:h, x:x+self.patch_size]\n",
    "                image_patches.append(image_patch)\n",
    "                \n",
    "                if mask is not None:\n",
    "                    mask_patch = mask[h-self.patch_size:h, x:x+self.patch_size]\n",
    "                    mask_patches.append(mask_patch)\n",
    "        \n",
    "        if w % self.patch_size != 0:\n",
    "            for y in range(0, h - self.patch_size + 1, stride):\n",
    "                image_patch = image[y:y+self.patch_size, w-self.patch_size:w]\n",
    "                image_patches.append(image_patch)\n",
    "                \n",
    "                if mask is not None:\n",
    "                    mask_patch = mask[y:y+self.patch_size, w-self.patch_size:w]\n",
    "                    mask_patches.append(mask_patch)\n",
    "        \n",
    "        # Add bottom-right corner patch\n",
    "        if h % self.patch_size != 0 and w % self.patch_size != 0:\n",
    "            image_patch = image[h-self.patch_size:h, w-self.patch_size:w]\n",
    "            image_patches.append(image_patch)\n",
    "            \n",
    "            if mask is not None:\n",
    "                mask_patch = mask[h-self.patch_size:h, w-self.patch_size:w]\n",
    "                mask_patches.append(mask_patch)\n",
    "                \n",
    "        if mask is not None:\n",
    "            return image_patches, mask_patches\n",
    "        else:\n",
    "            return image_patches\n",
    "    \n",
    "    def augment_data(self, image, mask=None):\n",
    "        \"\"\"\n",
    "        Apply data augmentation to image and mask.\n",
    "        \n",
    "        Args:\n",
    "            image (numpy.ndarray): Input image.\n",
    "            mask (numpy.ndarray, optional): Input mask.\n",
    "            \n",
    "        Returns:\n",
    "            tuple: Augmented image and (if provided) mask.\n",
    "        \"\"\"\n",
    "        if not self.augment or image is None:\n",
    "            return image, mask\n",
    "            \n",
    "        # Choose a random augmentation\n",
    "        aug_type = np.random.choice(['flip_h', 'flip_v', 'rotate', 'none'])\n",
    "        \n",
    "        if aug_type == 'flip_h':\n",
    "            image = np.fliplr(image)\n",
    "            if mask is not None:\n",
    "                mask = np.fliplr(mask)\n",
    "                \n",
    "        elif aug_type == 'flip_v':\n",
    "            image = np.flipud(image)\n",
    "            if mask is not None:\n",
    "                mask = np.flipud(mask)\n",
    "                \n",
    "        elif aug_type == 'rotate':\n",
    "            k = np.random.choice([1, 2, 3])  # 90, 180, 270 degrees\n",
    "            image = np.rot90(image, k=k)\n",
    "            if mask is not None:\n",
    "                mask = np.rot90(mask, k=k)\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    def create_ndvi_band(self, image, nir_idx=3, red_idx=0):\n",
    "        \"\"\"\n",
    "        Create NDVI band from NIR and Red bands.\n",
    "        \n",
    "        Args:\n",
    "            image (numpy.ndarray): Multi-band satellite image.\n",
    "            nir_idx (int): Index of NIR band.\n",
    "            red_idx (int): Index of Red band.\n",
    "            \n",
    "        Returns:\n",
    "            numpy.ndarray: NDVI band.\n",
    "        \"\"\"\n",
    "        # Check if image has enough bands\n",
    "        if len(image.shape) < 3 or image.shape[2] <= max(nir_idx, red_idx):\n",
    "            print(\"Not enough bands for NDVI calculation\")\n",
    "            return None\n",
    "            \n",
    "        # Extract bands\n",
    "        nir = image[:, :, nir_idx].astype(np.float32)\n",
    "        red = image[:, :, red_idx].astype(np.float32)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        denominator = nir + red\n",
    "        denominator[denominator == 0] = 1\n",
    "        \n",
    "        # Calculate NDVI\n",
    "        ndvi = (nir - red) / denominator\n",
    "        \n",
    "        # Scale from [-1, 1] to [0, 1] for visualization\n",
    "        ndvi = (ndvi + 1) / 2\n",
    "        \n",
    "        return ndvi\n",
    "    \n",
    "    def apply_preprocessing(self, image, mask=None, normalize_method='minmax', extract_patches=True):\n",
    "        \"\"\"\n",
    "        Apply all preprocessing steps to image and mask.\n",
    "        \n",
    "        Args:\n",
    "            image (numpy.ndarray): Input image.\n",
    "            mask (numpy.ndarray, optional): Input mask.\n",
    "            normalize_method (str): Normalization method.\n",
    "            extract_patches (bool): Whether to extract patches.\n",
    "            \n",
    "        Returns:\n",
    "            list or numpy.ndarray: Preprocessed image(s) and mask(s).\n",
    "        \"\"\"\n",
    "        if image is None:\n",
    "            return None, None\n",
    "            \n",
    "        # Normalize\n",
    "        norm_image = self.normalize_image(image, method=normalize_method)\n",
    "        \n",
    "        if extract_patches:\n",
    "            # Extract patches\n",
    "            if mask is not None:\n",
    "                image_patches, mask_patches = self.extract_patches(norm_image, mask)\n",
    "                \n",
    "                # Augment patches\n",
    "                if self.augment:\n",
    "                    for i in range(len(image_patches)):\n",
    "                        image_patches[i], mask_patches[i] = self.augment_data(image_patches[i], mask_patches[i])\n",
    "                        \n",
    "                return image_patches, mask_patches\n",
    "            else:\n",
    "                image_patches = self.extract_patches(norm_image)\n",
    "                \n",
    "                # Augment patches\n",
    "                if self.augment:\n",
    "                    for i in range(len(image_patches)):\n",
    "                        image_patches[i], _ = self.augment_data(image_patches[i])\n",
    "                        \n",
    "                return image_patches\n",
    "        else:\n",
    "            # Just normalize and potentially augment\n",
    "            if self.augment:\n",
    "                norm_image, mask = self.augment_data(norm_image, mask)\n",
    "                \n",
    "            return norm_image, mask\n",
    "\n",
    "# Create a preprocessor\n",
    "preprocessor = SatelliteImagePreprocessor(patch_size=256, overlap=0.2, augment=False)\n",
    "\n",
    "# Check if we have an image to process\n",
    "if 'image_rgb' in locals():\n",
    "    # Normalize the image\n",
    "    normalized_image = preprocessor.normalize_image(image_rgb)\n",
    "    \n",
    "    # Extract patches\n",
    "    image_patches = preprocessor.extract_patches(normalized_image)\n",
    "    \n",
    "    # Display the normalized image\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(normalized_image)\n",
    "    plt.title('Normalized Image')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Display some patches\n",
    "    n_patches = min(len(image_patches), 4)\n",
    "    if n_patches > 0:\n",
    "        plt.figure(figsize=(15, 4))\n",
    "        for i in range(n_patches):\n",
    "            plt.subplot(1, n_patches, i+1)\n",
    "            plt.imshow(image_patches[i])\n",
    "            plt.title(f\"Patch {i+1}\")\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Total patches extracted: {len(image_patches)}\")\n",
    "    else:\n",
    "        print(\"No patches were extracted. The image may be too small.\")\n",
    "    \n",
    "    # Try to create NDVI (assuming 4+ bands; will not work with RGB)\n",
    "    if len(image_rgb.shape) >= 3 and image_rgb.shape[2] >= 4:\n",
    "        ndvi = preprocessor.create_ndvi_band(image_rgb)\n",
    "        if ndvi is not None:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.imshow(ndvi, cmap='RdYlGn')\n",
    "            plt.title('NDVI')\n",
    "            plt.colorbar(label='NDVI')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"Not enough bands to calculate NDVI. Using grayscale instead.\")\n",
    "        # Convert to grayscale as a fallback\n",
    "        gray_image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.imshow(gray_image, cmap='gray')\n",
    "        plt.title('Grayscale Image')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No image available for preprocessing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing U-Net for Satellite Image Segmentation\n",
    "\n",
    "U-Net is a convolutional neural network designed for biomedical image segmentation, but it works exceptionally well for satellite imagery.\n",
    "\n",
    "## U-Net Architecture\n",
    "\n",
    "The U-Net architecture consists of:\n",
    "1. **Encoder Path (Contracting)**: Captures context through downsampling\n",
    "2. **Decoder Path (Expanding)**: Precise localization through upsampling\n",
    "3. **Skip Connections**: Combine high-resolution features with upsampled features\n",
    "\n",
    "## Mathematical Background\n",
    "\n",
    "The U-Net is trained to minimize a loss function between the predicted segmentation $\\hat{y}$ and ground truth $y$:\n",
    "\n",
    "$$\\mathcal{L}(\\hat{y}, y) = -\\sum_{i,j} w_{i,j} [y_{i,j} \\log(\\hat{y}_{i,j}) + (1 - y_{i,j}) \\log(1 - \\hat{y}_{i,j})]$$\n",
    "\n",
    "where $w_{i,j}$ are weights that can be used to emphasize certain pixels or classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Double Convolution block for U-Net: (Conv2d -> BatchNorm -> ReLU) × 2\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"\n",
    "    Downscaling with maxpool then double conv\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"\n",
    "    Upscaling then double conv\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Use ConvTranspose2d or bilinear upsampling\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        \n",
    "        # Input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "        \n",
    "        # Pad x1 if necessary\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        \n",
    "        # Concatenate along the channel dimension\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Output convolution block\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"\n",
    "    U-Net architecture for image segmentation\n",
    "    \"\"\"\n",
    "    def __init__(self, n_channels=3, n_classes=1, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "        \n",
    "        # Encoder (downsampling path)\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        \n",
    "        # Decoder (upsampling path)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "# Define Dice Loss for segmentation\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        \n",
    "    def forward(self, predictions, targets):\n",
    "        # Flatten predictions and targets\n",
    "        predictions = predictions.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        # Calculate intersection and union\n",
    "        intersection = (predictions * targets).sum()\n",
    "        union = predictions.sum() + targets.sum()\n",
    "        \n",
    "        # Calculate dice coefficient and loss\n",
    "        dice = (2. * intersection + self.smooth) / (union + self.smooth)\n",
    "        loss = 1 - dice\n",
    "        \n",
    "        return loss\n",
    "\n",
    "# Create a simple dataset class for demonstration\n",
    "class SatelliteSegmentationDataset(Dataset):\n",
    "    def __init__(self, images, masks, transform=None):\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        mask = self.masks[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # Convert to tensor if not already\n",
    "        if not isinstance(image, torch.Tensor):\n",
    "            image = torch.from_numpy(image.transpose((2, 0, 1))).float()\n",
    "            \n",
    "        if not isinstance(mask, torch.Tensor):\n",
    "            mask = torch.from_numpy(mask).float()\n",
    "            \n",
    "        # Ensure image has 3 channels\n",
    "        if image.shape[0] == 1:\n",
    "            image = image.repeat(3, 1, 1)\n",
    "        elif image.shape[0] > 3:\n",
    "            image = image[:3]\n",
    "            \n",
    "        # Normalize image if needed\n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "            \n",
    "        # Ensure mask is binary\n",
    "        if mask.max() > 1.0:\n",
    "            mask = (mask > 0).float()\n",
    "            \n",
    "        return image, mask.unsqueeze(0)  # Add channel dimension to mask\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=5):\n",
    "    \"\"\"\n",
    "    Train the U-Net model\n",
    "    \n",
    "    Args:\n",
    "        model: Model to train\n",
    "        train_loader: Training data loader\n",
    "        val_loader: Validation data loader\n",
    "        criterion: Loss function\n",
    "        optimizer: Optimizer\n",
    "        device: Device to use\n",
    "        num_epochs: Number of epochs to train\n",
    "        \n",
    "    Returns:\n",
    "        Trained model and training history\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_dice': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        # Training loop\n",
    "        for images, masks in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(torch.sigmoid(outputs), masks)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        # Calculate average training loss\n",
    "        train_loss /= len(train_loader)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        \n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_dice = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images = images.to(device)\n",
    "                masks = masks.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(torch.sigmoid(outputs), masks)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                # Calculate Dice coefficient for validation\n",
    "                dice = 1 - loss.item()  # Since we're using Dice Loss\n",
    "                val_dice += dice\n",
    "                \n",
    "        val_loss /= len(val_loader)\n",
    "        val_dice /= len(val_loader)\n",
    "        \n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_dice'].append(val_dice)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "              f\"Train Loss: {train_loss:.4f}, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, \"\n",
    "              f\"Val Dice: {val_dice:.4f}\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# Generate some synthetic data for demonstration\n",
    "def generate_synthetic_data(num_samples=100, img_size=128):\n",
    "    \"\"\"Generate synthetic satellite images and segmentation masks\"\"\"\n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        # Create a synthetic image with some shapes\n",
    "        image = np.ones((img_size, img_size, 3), dtype=np.float32) * 0.1\n",
    "        mask = np.zeros((img_size, img_size), dtype=np.float32)\n",
    "        \n",
    "        # Add random shapes\n",
    "        num_shapes = np.random.randint(1, 5)\n",
    "        for _ in range(num_shapes):\n",
    "            # Random shape type\n",
    "            shape_type = np.random.choice(['circle', 'rectangle'])\n",
    "            \n",
    "            # Random position and size\n",
    "            x = np.random.randint(10, img_size-10)\n",
    "            y = np.random.randint(10, img_size-10)\n",
    "            size = np.random.randint(10, 40)\n",
    "            \n",
    "            # Random color for image\n",
    "            color = np.random.rand(3) * 0.8 + 0.2\n",
    "            \n",
    "            if shape_type == 'circle':\n",
    "                # Draw circle on image and mask\n",
    "                cv2.circle(image, (x, y), size, color, -1)\n",
    "                cv2.circle(mask, (x, y), size, 1, -1)\n",
    "            else:\n",
    "                # Draw rectangle on image and mask\n",
    "                x2, y2 = x + size, y + size\n",
    "                cv2.rectangle(image, (x, y), (x2, y2), color, -1)\n",
    "                cv2.rectangle(mask, (x, y), (x2, y2), 1, -1)\n",
    "        \n",
    "        images.append(image)\n",
    "        masks.append(mask)\n",
    "    \n",
    "    return images, masks\n",
    "\n",
    "# Create synthetic dataset for demonstration\n",
    "print(\"Generating synthetic data for demonstration...\")\n",
    "synthetic_images, synthetic_masks = generate_synthetic_data(num_samples=100, img_size=128)\n",
    "\n",
    "# Display a few examples\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(synthetic_images[i])\n",
    "    plt.contour(synthetic_masks[i], colors='r', levels=[0.5])\n",
    "    plt.title(f\"Sample {i+1}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_size = int(0.8 * len(synthetic_images))\n",
    "train_images = synthetic_images[:train_size]\n",
    "train_masks = synthetic_masks[:train_size]\n",
    "val_images = synthetic_images[train_size:]\n",
    "val_masks = synthetic_masks[train_size:]\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SatelliteSegmentationDataset(train_images, train_masks)\n",
    "val_dataset = SatelliteSegmentationDataset(val_images, val_masks)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "model = UNet(n_channels=3, n_classes=1, bilinear=True)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = DiceLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Train the model (using a small number of epochs for demonstration)\n",
    "print(\"\\nTraining U-Net model...\")\n",
    "model, history = train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=2)\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss History')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['val_dice'], label='Validation Dice')\n",
    "plt.title('Dice Coefficient')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Dice')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test the model on a sample\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_idx = np.random.randint(len(val_images))\n",
    "    sample_image = val_images[sample_idx]\n",
    "    sample_mask = val_masks[sample_idx]\n",
    "    \n",
    "    # Convert to tensor\n",
    "    sample_tensor = torch.from_numpy(sample_image.transpose((2, 0, 1))).float().unsqueeze(0).to(device)\n",
    "    \n",
    "    # Predict\n",
    "    output = model(sample_tensor)\n",
    "    pred_mask = torch.sigmoid(output).cpu().squeeze().numpy() > 0.5\n",
    "    \n",
    "    # Display results\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(sample_image)\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(sample_mask, cmap='gray')\n",
    "    plt.title('Ground Truth')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(pred_mask, cmap='gray')\n",
    "    plt.title('Predicted Mask')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate Dice coefficient\n",
    "    dice = 2 * np.sum(pred_mask * sample_mask) / (np.sum(pred_mask) + np.sum(sample_mask) + 1e-8)\n",
    "    print(f\"Dice coefficient on test sample: {dice:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Edge Detection\n",
    "Use Canny edge detection to find edges in the binary image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv2.Canny(binary_image, 100, 200)\n",
    "\n",
    "# Display the edges \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(edges, cmap='gray')\n",
    "plt.title('Edge Detection using Canny')\n",
    "plt.axis('off')  # Hide the axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment the Image Using Contours\n",
    "Find and draw contours on the original image to segment it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, _ = cv2.findContours(binary_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "image_with_contours = image_rgb.copy()\n",
    "cv2.drawContours(image_with_contours, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "# image with contours \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(image_with_contours)\n",
    "plt.title('Image with Contours')\n",
    "plt.axis('off')  \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
