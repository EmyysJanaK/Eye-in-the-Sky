{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import the necessary libraries such as pandas, numpy, sklearn, and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "Load the dataset that will be used for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('path/to/your/dataset.csv')\n",
    "\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Numerical Features\n",
    "Extract numerical features using techniques such as normalization, standardization, and polynomial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = data.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "normalized_features = min_max_scaler.fit_transform(data[numerical_cols])\n",
    "normalized_df = pd.DataFrame(normalized_features, columns=numerical_cols)\n",
    "\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "standardized_features = standard_scaler.fit_transform(data[numerical_cols])\n",
    "standardized_df = pd.DataFrame(standardized_features, columns=numerical_cols)\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly_features = poly.fit_transform(data[numerical_cols])\n",
    "poly_feature_names = poly.get_feature_names_out(numerical_cols)\n",
    "poly_df = pd.DataFrame(poly_features, columns=poly_feature_names)\n",
    "\n",
    "\n",
    "normalized_df.head(), standardized_df.head(), poly_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Categorical Features\n",
    "Extract categorical features using techniques such as one-hot encoding, label encoding, and frequency encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "categorical_cols = data.select_dtypes(include=[object]).columns\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "one_hot_encoded_features = one_hot_encoder.fit_transform(data[categorical_cols])\n",
    "one_hot_encoded_df = pd.DataFrame(one_hot_encoded_features, columns=one_hot_encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoded_df = data[categorical_cols].apply(label_encoder.fit_transform)\n",
    "\n",
    "frequency_encoded_df = data[categorical_cols].apply(lambda x: x.map(x.value_counts()) / len(x))\n",
    "\n",
    "one_hot_encoded_df.head(), label_encoded_df.head(), frequency_encoded_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Text Features\n",
    "Extract text features using techniques such as TF-IDF, word embeddings, and n-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text_cols = data.select_dtypes(include=[object]).columns\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(data[text_cols[0]])\n",
    "tfidf_df = pd.DataFrame(tfidf_features.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "ngram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "ngram_features = ngram_vectorizer.fit_transform(data[text_cols[0]])\n",
    "ngram_df = pd.DataFrame(ngram_features.toarray(), columns=ngram_vectorizer.get_feature_names_out())\n",
    "\n",
    "tfidf_df.head(), ngram_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Image Features\n",
    "Extract image features using techniques such as edge detection, color histograms, and convolutional neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "\n",
    "img_path = 'path/to/your/image.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(img_rgb)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "edges = cv2.Canny(img, 100, 200)\n",
    "\n",
    "plt.imshow(edges, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "color_hist = cv2.calcHist([img], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "color_hist = cv2.normalize(color_hist, color_hist).flatten()\n",
    "\n",
    "plt.plot(color_hist)\n",
    "plt.show()\n",
    "\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "hog_features, hog_image = hog(gray_img, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True, multichannel=False)\n",
    "\n",
    "plt.imshow(hog_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
    "\n",
    "img_resized = cv2.resize(img_rgb, (224, 224))\n",
    "x = image.img_to_array(img_resized)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "vgg16_features = model.predict(x)\n",
    "vgg16_features = vgg16_features.flatten()\n",
    "\n",
    "vgg16_features.shape\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
