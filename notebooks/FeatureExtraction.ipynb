{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Satellite Image Feature Extraction Using Deep Learning\n",
    "\n",
    "## Introduction\n",
    "\n",
    "this notebook extracts meaningful features from satellite imagery using state-of-the-art deep learning techniques. These features are important for various downstream tasks such as land cover classification, object detection, and change detection.\n",
    "\n",
    "### Mathematical Foundations\n",
    "\n",
    "In deep learning, features are extracted through convolutional layers, which perform the following operation:\n",
    "\n",
    "$$F(i,j) = \\sum_m \\sum_n I(i+m, j+n) K(m,n)$$\n",
    "\n",
    "where $I$ is the input image, $K$ is the kernel/filter, and $F$ is the resulting feature map.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "1. Load and preprocess satellite imagery\n",
    "2. Extract features using pre-trained CNNs (Transfer Learning)\n",
    "3. Visualize extracted features and feature maps\n",
    "4. Dimensionality reduction for feature analysis (PCA, t-SNE)\n",
    "5. Save features for downstream tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "from skimage import io, transform\n",
    "from skimage.feature import hog\n",
    "\n",
    "# Deep learning imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights, vgg16, VGG16_Weights\n",
    "\n",
    "# Feature visualization and dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Satellite Imagery Dataset\n",
    "\n",
    "Satellite images have unique characteristics that require specialized handling:\n",
    "\n",
    "1. **Multi-spectral data**: Satellite images often contain multiple bands beyond RGB\n",
    "2. **Geospatial metadata**: Images are georeferenced with coordinate systems\n",
    "3. **Large file sizes**: Satellite images can be extremely large\n",
    "4. **Various formats**: Common formats include GeoTIFF, JP2, and NITF\n",
    "\n",
    "Let's create a utility class to handle satellite image loading efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteImageLoader:\n",
    "    \"\"\"\n",
    "    A class to load and preprocess satellite images.\n",
    "    \n",
    "    Attributes:\n",
    "        data_dir (str): Directory containing the satellite images.\n",
    "        transform (callable): Transformations to apply to the images.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Initialize the SatelliteImageLoader.\n",
    "        \n",
    "        Args:\n",
    "            data_dir (str): Directory containing the satellite images.\n",
    "            transform (callable, optional): Transformations to apply to the images.\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = self._get_image_files()\n",
    "        \n",
    "    def _get_image_files(self):\n",
    "        \"\"\"\n",
    "        Get all image files in the data directory.\n",
    "        \n",
    "        Returns:\n",
    "            list: List of image file paths.\n",
    "        \"\"\"\n",
    "        image_extensions = ('.tif', '.jpg', '.png')\n",
    "        if os.path.exists(self.data_dir):\n",
    "            return [os.path.join(self.data_dir, f) for f in os.listdir(self.data_dir) \n",
    "                    if f.lower().endswith(image_extensions)]\n",
    "        else:\n",
    "            print(f\"Directory {self.data_dir} not found\")\n",
    "            return []\n",
    "    \n",
    "    def load_image(self, idx):\n",
    "        \"\"\"\n",
    "        Load a specific image by index.\n",
    "        \n",
    "        Args:\n",
    "            idx (int): Index of the image to load.\n",
    "            \n",
    "        Returns:\n",
    "            PIL.Image: Loaded image.\n",
    "        \"\"\"\n",
    "        image_path = self.image_files[idx]\n",
    "        \n",
    "        # Check if it's a GeoTIFF file\n",
    "        if image_path.lower().endswith('.tif'):\n",
    "            try:\n",
    "                with rasterio.open(image_path) as src:\n",
    "                    # Read all bands and convert to RGB if needed\n",
    "                    img = src.read()\n",
    "                    # If more than 3 bands, take first 3 (assuming RGB)\n",
    "                    if img.shape[0] > 3:\n",
    "                        img = img[:3]\n",
    "                    # Transpose to (H, W, C) format for display\n",
    "                    img = np.transpose(img, (1, 2, 0))\n",
    "                    # Normalize to 0-255 range if needed\n",
    "                    if img.max() > 0:\n",
    "                        img = (img / img.max() * 255).astype(np.uint8)\n",
    "                    return Image.fromarray(img)\n",
    "            except:\n",
    "                print(f\"Error opening {image_path} with rasterio. Trying with PIL...\")\n",
    "                return Image.open(image_path).convert('RGB')\n",
    "        else:\n",
    "            # For regular image formats\n",
    "            return Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    def get_batch(self, batch_size=4):\n",
    "        \"\"\"\n",
    "        Get a batch of random images.\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int): Number of images to return.\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Batch of images.\n",
    "        \"\"\"\n",
    "        if len(self.image_files) == 0:\n",
    "            print(\"No image files found\")\n",
    "            return None\n",
    "            \n",
    "        indices = np.random.choice(len(self.image_files), min(batch_size, len(self.image_files)), replace=False)\n",
    "        images = [self.load_image(idx) for idx in indices]\n",
    "        \n",
    "        if self.transform:\n",
    "            images = [self.transform(img) for img in images]\n",
    "            return torch.stack(images)\n",
    "        return images\n",
    "    \n",
    "    def visualize_samples(self, num_samples=4, figsize=(12, 12)):\n",
    "        \"\"\"\n",
    "        Visualize a random sample of images.\n",
    "        \n",
    "        Args:\n",
    "            num_samples (int): Number of images to visualize.\n",
    "            figsize (tuple): Figure size (width, height).\n",
    "        \"\"\"\n",
    "        if len(self.image_files) == 0:\n",
    "            print(\"No image files found\")\n",
    "            return\n",
    "            \n",
    "        indices = np.random.choice(len(self.image_files), min(num_samples, len(self.image_files)), replace=False)\n",
    "        \n",
    "        plt.figure(figsize=figsize)\n",
    "        for i, idx in enumerate(indices):\n",
    "            img = self.load_image(idx)\n",
    "            plt.subplot(int(np.ceil(num_samples / 2)), 2, i+1)\n",
    "            plt.imshow(img)\n",
    "            plt.title(f\"Sample {i+1}: {os.path.basename(self.image_files[idx])}\")\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Set the path to your satellite image directory\n",
    "DATA_DIR = \"../data/sentinelsat\"  # Update this path as needed\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(DATA_DIR):\n",
    "    # Define image transformations for preprocessing\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize to model input size\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet normalization\n",
    "    ])\n",
    "    \n",
    "    # Create the image loader\n",
    "    loader = SatelliteImageLoader(DATA_DIR)\n",
    "    \n",
    "    # Visualize some sample images\n",
    "    loader.visualize_samples(num_samples=4)\n",
    "else:\n",
    "    print(f\"Data directory {DATA_DIR} not found. Please update the path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "\n",
    "We'll leverage a pre-trained ResNet50 model:\n",
    "- Trained on millions of images (ImageNet)\n",
    "- Strong feature representations\n",
    "- Adaptable to satellite imagery through fine-tuning\n",
    "\n",
    "The mathematical formulation for feature extraction via CNN is:\n",
    "\n",
    "$$f(x) = \\phi_L(...\\phi_2(\\phi_1(x;w_1);w_2)...;w_L)$$\n",
    "\n",
    "Where $\\phi_l$ represents the function of layer $l$ with parameters $w_l$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFeatureExtractor:\n",
    "    \"\"\"\n",
    "    A class for extracting deep features from images using pre-trained models.\n",
    "    \n",
    "    Attributes:\n",
    "        model (torch.nn.Module): The pre-trained model for feature extraction.\n",
    "        layer_name (str): The name of the layer from which to extract features.\n",
    "        transform (callable): Transformations to apply to the images.\n",
    "        device (torch.device): The device to use for computation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name='resnet50', layer_name='avgpool', device=device):\n",
    "        \"\"\"\n",
    "        Initialize the feature extractor.\n",
    "        \n",
    "        Args:\n",
    "            model_name (str): Name of the pre-trained model to use ('resnet50' or 'vgg16').\n",
    "            layer_name (str): Name of the layer from which to extract features.\n",
    "            device (torch.device): Device to use for computation.\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        \n",
    "        # Load the pre-trained model\n",
    "        if model_name == 'resnet50':\n",
    "            self.model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        elif model_name == 'vgg16':\n",
    "            self.model = vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "        else:\n",
    "            raise ValueError(f\"Model {model_name} not supported.\")\n",
    "            \n",
    "        self.model = self.model.to(device)\n",
    "        self.model.eval()  # Set to evaluation mode\n",
    "        \n",
    "        self.layer_name = layer_name\n",
    "        self.features = None\n",
    "        \n",
    "        # Register hook to capture features\n",
    "        self._register_hook()\n",
    "        \n",
    "        # Default transform for preprocessing\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def _register_hook(self):\n",
    "        \"\"\"\n",
    "        Register a forward hook to capture features from the specified layer.\n",
    "        \"\"\"\n",
    "        def hook_fn(module, input, output):\n",
    "            self.features = output.detach()\n",
    "            \n",
    "        # Find the target layer and register hook\n",
    "        if hasattr(self.model, self.layer_name):\n",
    "            getattr(self.model, self.layer_name).register_forward_hook(hook_fn)\n",
    "        else:\n",
    "            # For other layers, need to find them dynamically\n",
    "            for name, module in self.model.named_modules():\n",
    "                if name == self.layer_name:\n",
    "                    module.register_forward_hook(hook_fn)\n",
    "                    break\n",
    "    \n",
    "    def extract_features(self, images, flatten=True):\n",
    "        \"\"\"\n",
    "        Extract features from input images.\n",
    "        \n",
    "        Args:\n",
    "            images (torch.Tensor or PIL.Image or list): Input images.\n",
    "            flatten (bool): Whether to flatten the features.\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Extracted features.\n",
    "        \"\"\"\n",
    "        # Handle different input types\n",
    "        if isinstance(images, list) and isinstance(images[0], Image.Image):\n",
    "            # List of PIL images\n",
    "            tensor_images = torch.stack([self.transform(img) for img in images])\n",
    "        elif isinstance(images, Image.Image):\n",
    "            # Single PIL image\n",
    "            tensor_images = self.transform(images).unsqueeze(0)\n",
    "        else:\n",
    "            # Already a tensor\n",
    "            tensor_images = images\n",
    "        \n",
    "        tensor_images = tensor_images.to(self.device)\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        with torch.no_grad():\n",
    "            _ = self.model(tensor_images)\n",
    "            \n",
    "        # Get the features\n",
    "        features = self.features\n",
    "        \n",
    "        # Flatten if requested\n",
    "        if flatten:\n",
    "            features = features.view(features.size(0), -1)\n",
    "            \n",
    "        return features\n",
    "\n",
    "# Create a feature extractor\n",
    "feature_extractor = DeepFeatureExtractor(model_name='resnet50', layer_name='avgpool')\n",
    "\n",
    "# Check if data directory exists\n",
    "if os.path.exists(DATA_DIR) and len(os.listdir(DATA_DIR)) > 0:\n",
    "    # Create the image loader with no transform (will be applied in extractor)\n",
    "    loader = SatelliteImageLoader(DATA_DIR, transform=None)\n",
    "    \n",
    "    # Load some sample images\n",
    "    num_samples = min(4, len(loader.image_files))\n",
    "    if num_samples > 0:\n",
    "        indices = np.random.choice(len(loader.image_files), num_samples, replace=False)\n",
    "        images = [loader.load_image(idx) for idx in indices]\n",
    "        \n",
    "        # Extract features\n",
    "        features = feature_extractor.extract_features(images)\n",
    "        \n",
    "        print(f\"Extracted features shape: {features.shape}\")\n",
    "        print(f\"First few feature values for first image: {features[0, :5]}\")\n",
    "else:\n",
    "    print(\"No images found in the data directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureMapVisualizer:\n",
    "    \"\"\"\n",
    "    A class for visualizing CNN feature maps.\n",
    "    \n",
    "    Attributes:\n",
    "        model (torch.nn.Module): The model for feature extraction.\n",
    "        device (torch.device): The device to use for computation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name='resnet50', device=device):\n",
    "        \"\"\"\n",
    "        Initialize the feature map visualizer.\n",
    "        \n",
    "        Args:\n",
    "            model_name (str): Name of the pre-trained model.\n",
    "            device (torch.device): Device to use for computation.\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        \n",
    "        # Load the model\n",
    "        if model_name == 'resnet50':\n",
    "            self.model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        elif model_name == 'vgg16':\n",
    "            self.model = vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "        else:\n",
    "            raise ValueError(f\"Model {model_name} not supported.\")\n",
    "            \n",
    "        self.model = self.model.to(device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Store feature maps\n",
    "        self.feature_maps = {}\n",
    "        \n",
    "        # Register hooks\n",
    "        self._register_hooks()\n",
    "        \n",
    "        # Default transform\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def _register_hooks(self):\n",
    "        \"\"\"\n",
    "        Register forward hooks to capture feature maps from various layers.\n",
    "        \"\"\"\n",
    "        def hook_fn(name):\n",
    "            def hook(module, input, output):\n",
    "                self.feature_maps[name] = output.detach()\n",
    "            return hook\n",
    "        \n",
    "        # Register hooks for interesting layers in ResNet50\n",
    "        if hasattr(self.model, 'layer1'):\n",
    "            # ResNet architecture\n",
    "            self.model.layer1[0].conv1.register_forward_hook(hook_fn('layer1.0.conv1'))\n",
    "            self.model.layer2[0].conv1.register_forward_hook(hook_fn('layer2.0.conv1'))\n",
    "            self.model.layer3[0].conv1.register_forward_hook(hook_fn('layer3.0.conv1'))\n",
    "            self.model.layer4[0].conv1.register_forward_hook(hook_fn('layer4.0.conv1'))\n",
    "        elif hasattr(self.model, 'features'):\n",
    "            # VGG architecture\n",
    "            self.model.features[0].register_forward_hook(hook_fn('features.0'))  # First conv\n",
    "            self.model.features[5].register_forward_hook(hook_fn('features.5'))  # After first maxpool\n",
    "            self.model.features[10].register_forward_hook(hook_fn('features.10'))  # Middle\n",
    "            self.model.features[20].register_forward_hook(hook_fn('features.20'))  # Later\n",
    "    \n",
    "    def get_feature_maps(self, image):\n",
    "        \"\"\"\n",
    "        Get feature maps for an input image.\n",
    "        \n",
    "        Args:\n",
    "            image (PIL.Image or torch.Tensor): Input image.\n",
    "            \n",
    "        Returns:\n",
    "            dict: Feature maps from different layers.\n",
    "        \"\"\"\n",
    "        if isinstance(image, Image.Image):\n",
    "            tensor_image = self.transform(image).unsqueeze(0)\n",
    "        else:\n",
    "            tensor_image = image\n",
    "            \n",
    "        tensor_image = tensor_image.to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            _ = self.model(tensor_image)\n",
    "            \n",
    "        return self.feature_maps\n",
    "    \n",
    "    def visualize(self, image, num_features=16, figsize=(15, 10)):\n",
    "        \"\"\"\n",
    "        Visualize feature maps for an image.\n",
    "        \n",
    "        Args:\n",
    "            image (PIL.Image): Input image.\n",
    "            num_features (int): Number of feature maps to display per layer.\n",
    "            figsize (tuple): Figure size.\n",
    "        \"\"\"\n",
    "        # Get feature maps\n",
    "        feature_maps = self.get_feature_maps(image)\n",
    "        \n",
    "        # Display the original image\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(image)\n",
    "        plt.title(\"Original Image\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        # Display feature maps from each layer\n",
    "        for layer_name, feature_map in feature_maps.items():\n",
    "            # Move to CPU and convert to numpy\n",
    "            feature_map = feature_map[0].cpu().numpy()\n",
    "            \n",
    "            # Determine grid dimensions\n",
    "            n_features = min(num_features, feature_map.shape[0])\n",
    "            grid_size = int(np.ceil(np.sqrt(n_features)))\n",
    "            \n",
    "            plt.figure(figsize=figsize)\n",
    "            plt.suptitle(f\"Feature Maps: {layer_name}\")\n",
    "            \n",
    "            for i in range(n_features):\n",
    "                plt.subplot(grid_size, grid_size, i + 1)\n",
    "                \n",
    "                # Normalize for better visualization\n",
    "                feat = feature_map[i]\n",
    "                if feat.max() > feat.min():\n",
    "                    feat = (feat - feat.min()) / (feat.max() - feat.min())\n",
    "                \n",
    "                plt.imshow(feat, cmap='viridis')\n",
    "                plt.axis('off')\n",
    "                \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "# Create a feature map visualizer\n",
    "visualizer = FeatureMapVisualizer()\n",
    "\n",
    "# Check if data directory exists\n",
    "if os.path.exists(DATA_DIR) and len(os.listdir(DATA_DIR)) > 0:\n",
    "    # Load a sample image\n",
    "    loader = SatelliteImageLoader(DATA_DIR)\n",
    "    if len(loader.image_files) > 0:\n",
    "        sample_image = loader.load_image(0)  # Load the first image\n",
    "        \n",
    "        # Visualize feature maps\n",
    "        visualizer.visualize(sample_image, num_features=8)\n",
    "    else:\n",
    "        print(\"No images found in the data directory.\")\n",
    "else:\n",
    "    print(\"Data directory not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction and Feature Visualization\n",
    "\n",
    "High-dimensional features extracted from CNNs (e.g., 2048D from ResNet50) are difficult to visualize directly. We can use dimensionality reduction techniques to visualize these features in lower dimensions.\n",
    "\n",
    "## Principal Component Analysis (PCA)\n",
    "\n",
    "PCA projects data along directions of maximum variance:\n",
    "\n",
    "$$Z = X W$$\n",
    "\n",
    "Where:\n",
    "- $X$ is the mean-centered data matrix\n",
    "- $W$ is the matrix of eigenvectors of the covariance matrix $X^TX$\n",
    "- $Z$ is the projected data\n",
    "\n",
    "## t-Distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "\n",
    "t-SNE preserves local neighborhood structure by modeling similarities as conditional probabilities:\n",
    "\n",
    "$$p_{j|i} = \\frac{\\exp(-\\|x_i-x_j\\|^2/2\\sigma_i^2)}{\\sum_{k \\neq i}\\exp(-\\|x_i-x_k\\|^2/2\\sigma_i^2)}$$\n",
    "\n",
    "These visualizations help identify clusters, outliers, and patterns in the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dimensions(features, method='pca', n_components=2):\n",
    "    \"\"\"\n",
    "    Reduce dimensionality of features.\n",
    "    \n",
    "    Args:\n",
    "        features (torch.Tensor or np.ndarray): Features to reduce.\n",
    "        method (str): Reduction method ('pca' or 'tsne').\n",
    "        n_components (int): Number of components to keep.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Reduced features.\n",
    "    \"\"\"\n",
    "    # Convert to numpy if needed\n",
    "    if isinstance(features, torch.Tensor):\n",
    "        features = features.cpu().numpy()\n",
    "    \n",
    "    # Apply dimensionality reduction\n",
    "    if method.lower() == 'pca':\n",
    "        reducer = PCA(n_components=n_components)\n",
    "    elif method.lower() == 'tsne':\n",
    "        reducer = TSNE(n_components=n_components, random_state=42)\n",
    "    else:\n",
    "        raise ValueError(f\"Method {method} not supported. Use 'pca' or 'tsne'.\")\n",
    "    \n",
    "    reduced_features = reducer.fit_transform(features)\n",
    "    return reduced_features\n",
    "\n",
    "def visualize_features_2d(features, labels=None, method='pca', figsize=(10, 8)):\n",
    "    \"\"\"\n",
    "    Visualize features in 2D.\n",
    "    \n",
    "    Args:\n",
    "        features (torch.Tensor or np.ndarray): Features to visualize.\n",
    "        labels (np.ndarray, optional): Labels for coloring points.\n",
    "        method (str): Reduction method ('pca' or 'tsne').\n",
    "        figsize (tuple): Figure size.\n",
    "    \"\"\"\n",
    "    # Reduce to 2D\n",
    "    features_2d = reduce_dimensions(features, method=method, n_components=2)\n",
    "    \n",
    "    # Create plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    if labels is not None:\n",
    "        # Color by labels if provided\n",
    "        scatter = plt.scatter(features_2d[:, 0], features_2d[:, 1], c=labels, cmap='viridis', alpha=0.8)\n",
    "        plt.colorbar(scatter, label=\"Label\")\n",
    "    else:\n",
    "        plt.scatter(features_2d[:, 0], features_2d[:, 1], alpha=0.8)\n",
    "        \n",
    "    plt.title(f\"2D Feature Visualization using {method.upper()}\")\n",
    "    plt.xlabel(f\"{method.upper()} Component 1\")\n",
    "    plt.ylabel(f\"{method.upper()} Component 2\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_features_3d(features, labels=None, method='pca', figsize=(12, 10)):\n",
    "    \"\"\"\n",
    "    Visualize features in 3D.\n",
    "    \n",
    "    Args:\n",
    "        features (torch.Tensor or np.ndarray): Features to visualize.\n",
    "        labels (np.ndarray, optional): Labels for coloring points.\n",
    "        method (str): Reduction method ('pca' or 'tsne').\n",
    "        figsize (tuple): Figure size.\n",
    "    \"\"\"\n",
    "    # Reduce to 3D\n",
    "    features_3d = reduce_dimensions(features, method=method, n_components=3)\n",
    "    \n",
    "    # Create 3D plot\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    if labels is not None:\n",
    "        scatter = ax.scatter(features_3d[:, 0], features_3d[:, 1], features_3d[:, 2], \n",
    "                             c=labels, cmap='viridis', alpha=0.8)\n",
    "        fig.colorbar(scatter, ax=ax, label=\"Label\")\n",
    "    else:\n",
    "        ax.scatter(features_3d[:, 0], features_3d[:, 1], features_3d[:, 2], alpha=0.8)\n",
    "    \n",
    "    ax.set_title(f\"3D Feature Visualization using {method.upper()}\")\n",
    "    ax.set_xlabel(f\"{method.upper()} Component 1\")\n",
    "    ax.set_ylabel(f\"{method.upper()} Component 2\")\n",
    "    ax.set_zlabel(f\"{method.upper()} Component 3\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Check if data directory exists\n",
    "if os.path.exists(DATA_DIR) and len(os.listdir(DATA_DIR)) > 0:\n",
    "    # Create loader and extractor\n",
    "    loader = SatelliteImageLoader(DATA_DIR)\n",
    "    extractor = DeepFeatureExtractor(model_name='resnet50', layer_name='avgpool')\n",
    "    \n",
    "    # Load multiple images (use all available images, up to a reasonable number)\n",
    "    num_samples = min(20, len(loader.image_files))  # Limit to 20 images for visualization\n",
    "    \n",
    "    if num_samples > 0:\n",
    "        indices = np.random.choice(len(loader.image_files), num_samples, replace=False)\n",
    "        images = [loader.load_image(idx) for idx in indices]\n",
    "        \n",
    "        # Extract features\n",
    "        features = extractor.extract_features(images)\n",
    "        print(f\"Extracted features from {num_samples} images, shape: {features.shape}\")\n",
    "        \n",
    "        # Generate some dummy labels for visualization purposes\n",
    "        # In a real scenario, these would be your class labels or clusters\n",
    "        dummy_labels = np.random.randint(0, 3, size=num_samples)\n",
    "        \n",
    "        # Visualize features using PCA\n",
    "        print(\"Visualizing features using PCA...\")\n",
    "        visualize_features_2d(features, labels=dummy_labels, method='pca')\n",
    "        \n",
    "        # Visualize features using t-SNE\n",
    "        if num_samples >= 5:  # t-SNE works better with more samples\n",
    "            print(\"Visualizing features using t-SNE...\")\n",
    "            visualize_features_2d(features, labels=dummy_labels, method='tsne')\n",
    "    else:\n",
    "        print(\"No images found in the data directory.\")\n",
    "else:\n",
    "    print(\"Data directory not found or empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Features for Downstream Tasks\n",
    "\n",
    "After extracting features, we need to save them for later use in downstream tasks like classification, regression, or clustering.\n",
    "\n",
    "## Feature Storage Considerations\n",
    "\n",
    "1. **Format**: Store as NumPy arrays or PyTorch tensors\n",
    "2. **Metadata**: Include information about the source images and extraction parameters\n",
    "3. **Compression**: Consider compression for large feature sets\n",
    "4. **Indexing**: Enable efficient retrieval for specific images\n",
    "\n",
    "## Conclusion and Next Steps\n",
    "\n",
    "In this notebook, we have:\n",
    "\n",
    "1. **Loaded** satellite imagery data\n",
    "2. **Extracted** deep features using pre-trained CNNs\n",
    "3. **Visualized** feature maps to understand what the network detects\n",
    "4. **Reduced dimensions** to visualize the feature space\n",
    "5. **Saved features** for downstream applications\n",
    "\n",
    "These features can now be used for:\n",
    "- Land cover classification\n",
    "- Object detection\n",
    "- Change detection\n",
    "- Anomaly detection\n",
    "- And many more remote sensing applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features(features, file_paths, output_path):\n",
    "    \"\"\"\n",
    "    Save extracted features to disk.\n",
    "    \n",
    "    Args:\n",
    "        features (torch.Tensor or np.ndarray): Extracted features.\n",
    "        file_paths (list): List of image file paths.\n",
    "        output_path (str): Path to save the features.\n",
    "    \"\"\"\n",
    "    # Convert to numpy if needed\n",
    "    if isinstance(features, torch.Tensor):\n",
    "        features = features.cpu().numpy()\n",
    "    \n",
    "    # Create a dictionary with file paths and features\n",
    "    feature_dict = {\n",
    "        'file_paths': [os.path.basename(fp) for fp in file_paths],\n",
    "        'features': features,\n",
    "        'extraction_info': {\n",
    "            'model': 'ResNet50',\n",
    "            'layer': 'avgpool',\n",
    "            'date_extracted': pd.Timestamp.now().isoformat(),\n",
    "            'feature_dim': features.shape[1]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    # Save using numpy\n",
    "    np.save(output_path, feature_dict)\n",
    "    print(f\"Features saved to {output_path}\")\n",
    "    \n",
    "def load_features(input_path):\n",
    "    \"\"\"\n",
    "    Load saved features.\n",
    "    \n",
    "    Args:\n",
    "        input_path (str): Path to the saved features.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (file_paths, features, extraction_info)\n",
    "    \"\"\"\n",
    "    feature_dict = np.load(input_path, allow_pickle=True).item()\n",
    "    return feature_dict['file_paths'], feature_dict['features'], feature_dict.get('extraction_info', None)\n",
    "\n",
    "# Check if data directory exists and we've extracted features\n",
    "if os.path.exists(DATA_DIR) and 'features' in locals() and 'indices' in locals() and len(loader.image_files) > 0:\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = \"../output/features\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save features extracted earlier\n",
    "    file_paths = [loader.image_files[idx] for idx in indices]\n",
    "    output_path = os.path.join(output_dir, \"resnet50_features.npy\")\n",
    "    save_features(features, file_paths, output_path)\n",
    "    \n",
    "    # Test loading\n",
    "    loaded_paths, loaded_features, extraction_info = load_features(output_path)\n",
    "    print(f\"Loaded {len(loaded_paths)} file paths and features with shape {loaded_features.shape}\")\n",
    "    print(f\"Extraction info: {extraction_info}\")\n",
    "    \n",
    "    # Display a summary of what we've accomplished\n",
    "    print(\"\\n=== Feature Extraction Summary ===\")\n",
    "    print(f\"• Images processed: {num_samples}\")\n",
    "    print(f\"• Feature dimensions: {features.shape[1]}\")\n",
    "    print(f\"• Model used: ResNet50\")\n",
    "    print(f\"• Features saved to: {output_path}\")\n",
    "    \n",
    "    # Show what can be done with these features\n",
    "    print(\"\\n=== Next Steps ===\")\n",
    "    print(\"1. Use these features for classification tasks\")\n",
    "    print(\"2. Apply clustering to find patterns in the data\")\n",
    "    print(\"3. Train models for object detection or segmentation\")\n",
    "    print(\"4. Develop change detection algorithms\")\n",
    "else:\n",
    "    print(\"Unable to save features: either no data directory found or no features extracted.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
